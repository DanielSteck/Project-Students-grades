---
title: "Project_student_grades"
subtitle: "Programming languages for Data Science"
author: "Daniel Steck"
date: "04.07.2023"
format: 
  html:
    code-fold: true
    code-tools: true
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

# Academic Honesty Statement

I, Daniel Steck, hereby state that I have not communicated with or gained information in any way from my classmates or anyone other than the Professor during this exam, and that all work is my own.

# Introduction

This project was created within the modul "Programming languages for Data Science. Moreover, this project will follow the data science lifecycle, which consists of four main topics:

-   Plan

-   Data

-   Model

-   Deployment

The main focus within this project will be on the **Deployment** part.

![Data Science Lifecycle](Images/Data_Science_lifecycle.PNG)

# Plan

## Identify use case

## Frame the problem

## Identify variables

## Define metrics

# Data

Within this chapter the data will be ingested and analyzed. Furthermore the data is also added into a SQL database and will be used for making queries.

## SQL data analysis

Before the steps of the data science lifecycle are made, some SQL queries will be made on the data, in order to answer questions from our costumers.

First the DBI library is loaded and afterwards the data is added into the database.

```{r import_SQL_librarys}

library (DBI)
library(tidyverse)

```

```{r database_connection}

# Connection to database 
con <- dbConnect(RSQLite::SQLite(), ":memory:")

path_sql <- "https://raw.githubusercontent.com/DanielSteck/Project-Students-grades/main/exams.csv"

# Write data "gapminder" into database
dbWriteTable(con, "exams_sql", read_csv(path_sql, show_col_types = FALSE))

#show table in database

dbListTables(con)
```

### First look on the data

```{sql connection=con}

SELECT *
FROM exams_sql;

```

The dataset contains 1000 observation with eight variables. Three out of these 8 variables are the students performance on exams.

Show the first 10 observations:

```{sql connection=con}

SELECT *
FROM exams_sql
LIMIT 10;
```

It can be seen that the columns should be renamed as there are e.g. spaces included:

```{sql connection=con}

ALTER TABLE exams_sql
RENAME COLUMN "race/ethnicity" TO ethnicity

```

```{sql connection=con}
ALTER TABLE exams_sql
RENAME COLUMN "parental level of education" TO parent_education

```

```{sql connection=con}
ALTER TABLE exams_sql
RENAME COLUMN "test preparation course" TO prep_course
```

```{sql connection=con}

ALTER TABLE exams_sql
RENAME COLUMN "math score" TO math_score
```

```{sql connection=con}
ALTER TABLE exams_sql
RENAME COLUMN "reading score" TO reading_score
```

```{sql connection=con}
ALTER TABLE exams_sql
RENAME COLUMN "writing score" TO writing_score;
```

Check the renamed columns

```{sql connection=con}
SELECT *
FROM exams_sql
```

Lets have a look on the gender and their performance in math.

```{sql connection=con}

SELECT gender, "math_score"
FROM exams_sql;
```

### Data Exploration

How many different genders are in the dataset?

```{sql connection=con}

SELECT DISTINCT gender
FROM exams_sql;

```

How many different ethnicities are in the dataset?

```{sql connection=con}

SELECT DISTINCT ethnicity
FROM exams_sql;
```

How many different forms of parent_education are in the dataset?

```{sql connection=con}

SELECT DISTINCT parent_education
FROM exams_sql;
```

How many different lunch types are in the dataset?

```{sql connection=con}

SELECT DISTINCT lunch
FROM exams_sql;
```

How many different types of preparation courses are in the dataset?

```{sql connection=con}

SELECT DISTINCT prep_course
FROM exams_sql;

```

How many observations are in the data set?

```{sql connection=con}

SELECT 
  COUNT(*) as rows
FROM exams_sql;
```

How many observations are available for each parent_education

```{sql connection=con}

SELECT parent_education,
  COUNT(parent_education) AS amount_of_observations
FROM exams_sql
GROUP BY parent_education
ORDER BY amount_of_observations DESC;
```

How many students have a math score above 80?

```{sql connection=con}

SELECT 
  COUNT(*) as students_above_math_80
FROM exams_sql
WHERE math_score > 80;
```

Have a look at the obervations of students with more than 90 in reading score

```{sql connection=con}

SELECT *
FROM exams_sql
WHERE reading_score >90;

```

Check the obervations of all females with more than 90 in writing score. The result shall be ordered by writing score (decreasing)

```{sql connection=con}

SELECT*
FROM exams_sql
WHERE gender ="female" AND writing_score>90
ORDER BY writing_score DESC;

```

Check all observations of students with more than 90% in one of the exams and made NO prep_course

```{sql connection=con}
SELECT *
FROM exams_sql
WHERE prep_course = "none" AND (math_score>90 OR writing_score>90 OR reading_score>90);

```

What are the average exam scores of the different ethnicies?

```{sql connection=con}
SELECT ethnicity,
  AVG(math_score) as avg_math,
  AVG(reading_score) as avg_read,
  AVG(writing_score) as avg_write
FROM exams_sql
GROUP BY ethnicity;
```

What are the best exam scores?

```{sql connection=con}

SELECT 
  MAX(math_score) as max_math,
  MAX(reading_score) as max_read,
  MAX(writing_score) as max_write
FROM exams_sql;
```

What are the worst exam scores?

```{sql connection=con}

SELECT 
  MIN(math_score) as min_math,
  MIN(reading_score) as min_read,
  MIN(writing_score) as min_write
FROM exams_sql;
```

What are the average exam scores for the genders?

```{sql connection=con}

SELECT gender,
  (AVG(math_score) + AVG(reading_score) + AVG(writing_score)) /3 as avg_exams_score
FROM exams_sql
GROUP BY gender;
```

Show all obervations which are parents_education "high_school" and have an average score in exams between 80 and 90. Result shall be ordered descending by avg_exam_score

```{sql connection=con}

SELECT gender, ethnicity, parent_education, lunch, prep_course,
  (math_score + reading_score + writing_score) /3 as avg_exams_score
FROM exams_sql
WHERE parent_education = "high school" AND avg_exams_score BETWEEN 80 AND 90;
```

Show all male ethnicities which have an average_exams score less than 70. Order the avg_exams_score ascending.

```{sql connection=con}

SELECT ethnicity,
  (AVG(math_score) + AVG(reading_score) + AVG(writing_score)) /3 as avg_exams_score
FROM exams_sql
WHERE gender="male"
GROUP BY ethnicity
HAVING avg_exams_score < 70
ORDER BY avg_exams_score;
  

```

## Data ingestion

### Data Import

First of all the data will be imported

```{r read_csv}

library(tidyverse)

path <- "https://raw.githubusercontent.com/DanielSteck/Project-Students-grades/main/exams.csv"

exams <- read_csv(path, show_col_types = FALSE)

```

### Clean Data

Lets have a look on the first rows to get an expression of the data

```{r first_rows}

exams %>%
  slice(1:5)
  

```

Before further steps can be made, the columns names need to be corrected, als they are including spaces and special characters. To remove those, the janitor package will be used.

```{r janitor}
library(janitor)
exams <- exams %>%
  clean_names()
```

Beside the cleaning of the names, some variables shall be renamed in order to shorten the length.

```{r rename_columns}
exams <- rename(exams, ethnic_group = race_ethnicity)
exams <- rename(exams, parent_education = parental_level_of_education)
exams <- rename(exams, test_prep = test_preparation_course)
```

The available data consist of `r nrow(exams)`. The available features are `r names(exams)`.

### Missing data

Lets have a look on the description of the data to check the formats.

```{r glimpse}
glimpse (exams)
```
Are there any missing data? lets check it:

```{r missing_values_graphic}
library(visdat)
vis_dat(exams)
```

Alternative method for missing data:

```{r missing_values_num}
is.na(exams) %>% colSums()
```

There are no missing numbers in the dataset. Three variables (scores in the exam) are numeric, the other variables are characters.

### Format data

Lets have a look on the character columns and check if they should be formatted as factor.

```{r levels_gender}
exams %>%
  count(gender,
        sort = TRUE)
```

```{r levels_ethnic_group}
exams %>%
  count(ethnic_group,
        sort = TRUE)
```

```{r levels_parent_education}
exams %>%
  count(parent_education,
        sort = TRUE)
```
```{r levels_lunch}
exams %>%
  count(lunch,
        sort = TRUE)
```
```{r levels_test_prep}
exams %>%
  count(test_prep,
        sort = TRUE)
```
All character variables are having only a small amount of different levels. Therefore all character variables shall be transferred as factor.

```{r char_to_factor}
exams <- 
  exams %>% 
  mutate(across(where(is.character), as.factor))
```

### Create new variables

Target of this project is to predict the students performance on exams. Therefore an additional column shall be added. This column shall include the average exam score of the students.

```{r new_column_avg_score}
exams <- exams%>%
  mutate (avg_score = (math_score + reading_score + writing_score)/3)
```

As all other variables are not numeric, no further new variables can be created.

### Data overview

After succesfully cleaning, formatting and checking the data, lets have an overview of the data with the package *skimr*: 

```{r skimr}
library(skimr)
skim(exams)
```
**beschreiben!**

### Define features and outcome variable

In advance of the data splitting the definition of the target variable and the feature variables shall be made.

The performance in the exams shall be predicted, for this the average performance is sufficient. As the target is to predict the performance, the variables for math, reading and writing score must not be included into the feature list.

```{r outcome_and_features}
y_label <- 'avg_score'
features <- c('gender', 'ethnic_group', 'parent_education', 'lunch', 'test_prep')
X <- exams %>%
  select(all_of(features))
y <- exams %>%
  select(all_of(y_label))
```


## Data splitting

Before the data exploration can be started, the data shall be splitted into a training and test set.

To ensure that the training and test set is representative of the various categories of `avg_score` in the whole dataset, lets have a look on the histogram

```{r bins_target_variable}
exams %>%
  ggplot(aes(avg_score)) + 
  geom_histogram (bins=6) #tested several, 6 makes most sense 

```

The splitted data shall included equally data from each of the bins.In order the have the same results for each run, a fix seed is set.

Target is to have 80% of the data for training and 20% for testing.

```{r train_test_split}
library(rsample)

set.seed(50) #for reproducability

# split in train and test data
data_split <- initial_split (exams,
                             prop =4/5,
                             strat = avg_score,
                             breaks = 6)

# Create train dataframe
train_data <- training(data_split)

#create test data set
test_data <- testing(data_split)
```

Moreover a validation set shall be created. This shall be used to validate the later models. After best models is used, based on the validation set, the model can be tested with the test data.

```{r validation_set}
set.seed(12)

cv_folds <- 
  vfold_cv(train_data,
           v=5,
           strata = y_label,
           breaks = 6)
```


## Analyze data

## Define schema

## Anomaly detection

## Feature engineering

# Model

## Select algorithm

## Model training & tuning

## Evaluate model

# Deployment

## Validate model

## Deploy model

## Serve model

## Monitor model
